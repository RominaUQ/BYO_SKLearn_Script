{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "output_path = \"s3://\" + sess.default_bucket() + \"/DEMO-mnist\"\n",
    "prefix = \"DEMO-mnist\"\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data  and upload to S3\n",
    "trans = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "#batch_size = 100\n",
    "batch_size = 10\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=trans)\n",
    "train_loc = sess.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n",
    "train_loc\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=trans)\n",
    "test_loc = sess.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse arguments passed from the SageMaker API\n",
    "    to the container\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters sent by the client are passed as command-line arguments to the script\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "\n",
    "\n",
    "# Data directories\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "\n",
    "    # Model directory: we will use the default set by SageMaker, /opt/ml/model\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def evaluate_net(net, loader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        total += labels.shape[0]\n",
    "        correct += (torch.argmax(outputs, dim=1) == labels).float().sum().item()\n",
    "        \n",
    "    return correct / total\n",
    "\n",
    "## model save and load function\n",
    "def save_model(model, model_dir):\n",
    "    path = os.path.join(model_dir, \"model.pth\")\n",
    "    torch.save(net.state_dict(), path)\n",
    "    print(\"saving model to \" + model_dir)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = Net()\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    args, _ = parse_args()\n",
    "    \n",
    "trans = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "trainset = datasets.MNIST(args.train, train=True, download=True,transform=trans )\n",
    "#print(trainset)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "#print(trainloader)\n",
    "\n",
    "testset = datasets.MNIST(args.test, train=True, download=True,transform=trans )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()    \n",
    "\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "#   print(net(inputs).shape)\n",
    "#     assert torch.exp(net(inputs)).sum().item() == 100\n",
    "#     break\n",
    "    \n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(), lr=1e-2\n",
    ")\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        if i % 100 == 100 - 1:\n",
    "            clear_output(wait=True)\n",
    "            plt.plot(loss_history)\n",
    "            plt.show()\n",
    "            \n",
    "train_accuracy = evaluate_net(net, trainloader)    \n",
    "test_accuracy = evaluate_net(net, testloader)         \n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy}\\nTest Accuracy: {test_accuracy}')   \n",
    "\n",
    "save_model(net, args.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba925010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local_mode to True to run the training script on the machine that runs this notebook\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "est = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.7.1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type= instance_type,\n",
    "    instance_count=1,\n",
    "    volume_size=250,\n",
    "    output_path=output_path,\n",
    "   hyperparameters={\"batch-size\": batch_size},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"train\": train_loc, \"test\": test_loc}\n",
    "est.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor= est.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdec5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample(dataset, size=16):\n",
    "    index = np.argsort(np.random.random(len(dataset)))[:size]\n",
    "    images, labels = list(zip(*[dataset[i] for i in index]))\n",
    "    \n",
    "    return torch.unsqueeze(torch.cat(images, dim=0), 1), labels\n",
    "    \n",
    "images, labels = sample(testset)\n",
    "predicted_labels = predictor(images).argmax(1)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "for i, (image, label, predict_label) in enumerate(zip(images, labels, predicted_labels)):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    \n",
    "    ax.imshow(image.squeeze(0).detach().cpu().numpy())\n",
    "    ax.grid(False)\n",
    "    ax.text(1, 3, f'T: {label}', color='white')\n",
    "    ax.text(22, 25, f'P: {predict_label.item()}', color='yellow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
